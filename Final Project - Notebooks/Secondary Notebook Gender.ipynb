{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondary Notebook: Building A Corpus of Catalogue Entries\n",
    "This secondary notebook serves to build a corpus of documents that will improve the gender component of my analysis. I aim at creating a corpus with all the entries of the 40 catalogues of our initial corpus. This larger corpus aims at improving the dictionary of women's name. In this case, the more documents we have to build our dictionary, the more chance we will have to correcftly identifiy the gender value of a document. I decided to do this in a secondary notebook in order to maintain the narrative flow of the main notebook.\n",
    "\n",
    "To do so, I start from step [fill in] in the main Notebook. The catalogues imported have thus been cleaned once, and the same steps as Note book one will be completed in this notebook but for the word \"Hatun\", \"Hâtun\" and \"bt.\" instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1613-1615 galata 37.txt', '1577-1578 galata 7.txt', '1573-1591 galata 15.txt', '1663-1663 galata 90.txt', '1675-1676 istanbul 18.txt', '1618-1618 istanbul 3.txt', '1524-1530 uskudar 5.txt', '1594-1595 rumeli 21.txt', '1670-1671 eyup 82.txt', '1612-1643 haskoy 5.txt', '1641-1644 galata 65.txt', '1647-1649 rumeli 80.txt', '1582-1583 uskudar 56.txt', '1633-1633 rumeli 56.txt', '1590-1591 uskudar 84.txt', '1637-1638 eyup 37.txt', '1579-1580 uskudar 51.txt', '1655-1655 eyup 61.txt', '1546-1549 uskudar 2.txt', '1585-1587 eyup 3.txt', '1606-1607 galata 32.txt', '1691-1691 bab 54.txt', '1726-1738 istanbul 24.txt', '1679-1680 eyup 90.txt', '1615-1620 galata 46.txt', '1644-1644 eyup 49.txt', '1546-1549 uskudar 14.txt', '1563-1563 balat 2.txt', '1619-1620 eyup 19.txt', '1663-1664 istanbul 12.txt', '1685-1686 bab 46.txt', '1549-1556 uskudar 17 .txt', '1575-1576 Galata 5.txt', '1666-1667 bab 3.txt', '1534-1536 uskudar 9 .txt', '1674-1679 haskoy 10.txt', '1661-1662 eyup 74.txt', '1562-1563 uskudar 26.txt', '1513-1521 uskudar 1.txt', '1596-1599 galata 20.txt']\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/otzy/local_directory/Final Project/corpora/\"\n",
    "os.chdir(path)\n",
    "filenames = os.listdir(path)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for this time, our corpus is all of the catalogues entries. So thats about it, we can now loop through our files to uncover all possible woman names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [] # track paragraphs\n",
    "for filename in filenames:\n",
    "    with open(path+filename, 'r') as f:\n",
    "        string = f.read()\n",
    "    pos = 0 # initial position marker (assuming our keyword isn't at the very start)\n",
    "    while(pos>-1): # loop while we have a match\n",
    "        pos = string.find(\"hâtun\", pos+1) # find next match\n",
    "        leftNewLine = string.rfind(\"\\n\\n\", 0, pos) # find previous newline\n",
    "        rightNewLine = string.find(\"\\n\\n\", pos) # find next newline\n",
    "        paragraph = string[leftNewLine+2:rightNewLine] # isolate paragraph\n",
    "        if paragraph: # if we have a non-empty string\n",
    "            paragraphs.append(paragraph) # add it to the paragraphs\n",
    "    while(pos>-1): # loop while we have a match\n",
    "        pos = string.find(\"hatun\", pos+1) # find next match\n",
    "        leftNewLine = string.rfind(\"\\n\\n\", 0, pos) # find previous newline\n",
    "        rightNewLine = string.find(\"\\n\\n\", pos) # find next newline\n",
    "        paragraph = string[leftNewLine+2:rightNewLine] # isolate paragraph\n",
    "        if paragraph: # if we have a non-empty string\n",
    "            paragraphs.append(paragraph) # add it to the paragraphs\n",
    "    while(pos>-1): # loop while we have a match\n",
    "        pos = string.find(\"Hâtun\", pos+1) # find next match\n",
    "        leftNewLine = string.rfind(\"\\n\\n\", 0, pos) # find previous newline\n",
    "        rightNewLine = string.find(\"\\n\\n\", pos) # find next newline\n",
    "        paragraph = string[leftNewLine+2:rightNewLine] # isolate paragraph\n",
    "        if paragraph: # if we have a non-empty string\n",
    "            paragraphs.append(paragraph) # add it to the paragraphs\n",
    "    while(pos>-1): # loop while we have a match\n",
    "        pos = string.find(\"Hatun\", pos+1) # find next match\n",
    "        leftNewLine = string.rfind(\"\\n\\n\", 0, pos) # find previous newline\n",
    "        rightNewLine = string.find(\"\\n\\n\", pos) # find next newline\n",
    "        paragraph = string[leftNewLine+2:rightNewLine] # isolate paragraph\n",
    "        if paragraph: # if we have a non-empty string\n",
    "            paragraphs.append(paragraph) # add it to the paragraphs\n",
    "os.mkdir(path+'kadinlara ilgili kaynaklar')\n",
    "os.chdir(path+'kadinlara ilgili kaynaklar')\n",
    "for i, paragraph in enumerate(paragraphs):\n",
    "    filename = '{0:03d}'.format(i)+'.txt'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4665\n"
     ]
    }
   ],
   "source": [
    "print(len(paragraphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have 4665 entries that contain the word Hatun (Lady), which most often comes with a women's name.\n",
    "\n",
    "Let's now extract these names. To do so I propose to craft our own tokenizer built in order to produce tokens with the words around Hatun. Thanks to the transliterators from Arabic to the Latin script, the proper names are identified with a capital letter! It's easier to tokenize the right one and to build the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "women_nametokens = RegexpTokenizer(r\"(?:[A-Z]\\w+\\s[A-Z]\\w+\\sbt.)|(?:[A-Z]\\w+\\s(?:Hatun|Hâtun))\") \n",
    "#RegexpTokenizer isn't something we have studied in class!\n",
    "#(?:[regex]) is a non-capturing group as required by the program. See link here:\n",
    "#http://www.nltk.org/api/nltk.tokenize.html?highlight=tokenizer#module-nltk.tokenize.regexp\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "path = \"/home/otzy/local_directory/Final Project/corpora/kadinlara ilgili kaynaklar/\"\n",
    "kadinCorpus = PlaintextCorpusReader(path, '.*txt')\n",
    "string = \"\"\n",
    "for fileid in kadinCorpus.fileids():\n",
    "    text = kadinCorpus.raw(fileid)# read each text and convert to lower case\n",
    "    tokens = women_nametokens.tokenize(text) # tokenize\n",
    "    tokens = \" \".join(tokens)\n",
    "    string += tokens\n",
    "#cleans the irregularities of string\n",
    "#Let's clean the list so that only the names remain, that \n",
    "#is, let us remove \"bt.\" and \"Hatun\"(both being marks of respect for ladies). \n",
    "#Afterwards, we'll be able to build a dictionary of only women names.\n",
    "string = re.sub(\"Hatun|Hâtun|bt.\", \"\", string) \n",
    "print(type(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this string into a dictionary in order to attribute gender values to particular documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms string back into list and dictionary\n",
    "women_names = nltk.word_tokenize(string)\n",
    "#create dictionary of names\n",
    "dict_women_names= {} # build a compilation of all of women's names\n",
    "#if not already in dictionary, add women_names as dict_women_names key\n",
    "for token in women_names:\n",
    "    if token not in dict_women_names:\n",
    "        dict_women_names[token] = 1 #gives value 1\n",
    "print(dict_women_names)\n",
    "print(len(dict_women_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any words that would create confusion(i.e. gender neutral, polysemic proper nouns, etc.), let's read the list, identify a few problematic variable, and use the dict.pop(arg1) to remove the undesirable arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = (\"Ermeni\", \"Emir\", \"Ayni\", \"Selçuk\", \"Envar\", \"Ali\", \"Edirneli\", \"Musâhibe\", \"Bahri\", \"Bâdıseher\", \"Mezbûre\", \"Usul\", \"Lütfi\", \"Melek\", \"Tomay\", \"Hammâmî\", \"Paşa\", \"Güllü\", \"Merhûm\", \"Belgradlı\", \"Hayati\", \"Ziyâde\", \"Ziyade\", \"Hoca\", \"Gülüm\", \"Abdülkerim\", \"Nâme\", \"Akpula\", \"Saadet\", \"Toklu\", \"Can\", \"Dilsiz\", \"Papa\", \"Reis\", \"Bey\", \"Murad\", \"Ağa\", \"Ramazan\", \"Hasan\", \"Beşe\", \"Süleyman\", \"Cihan\", \"Evin\", \"Boşanan\", \"Timurhan\", \"Tâcî\", \"Sultan\", \"Gevher\")\n",
    "#With some googling, it's easy to find inspiration to delete the entries enumerated above!\n",
    "#the solution I found proposed\n",
    "#thanks to https://stackoverflow.com/questions/8995611/removing-multiple-keys-from-a-dictionary-safely/30351294\n",
    "#defining a function isn't something we have done much in class!\n",
    "def entries_to_remove(entries, dict_women_names): \n",
    "    for key in entries:\n",
    "        if key in dict_women_names:\n",
    "            del dict_women_names[key]\n",
    "entries_to_remove(entries, dict_women_names)\n",
    "print(len(dict_women_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict_women_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go, our dictioanry is now ready to be added to the gender dictionary of the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
